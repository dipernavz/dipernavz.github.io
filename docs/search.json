[
  {
    "objectID": "part5.html",
    "href": "part5.html",
    "title": "Part 5",
    "section": "",
    "text": "# Imports\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.datasets import make_moons\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nRANDOM_STATE = 20\n\n# Helper method that plots the clusters generated by DBSCAN from \n# handson-ml3 in 09_unsupervised_learning.ipynb\ndef plot_dbscan(dbscan, X, size, show_xlabels=True, show_ylabels=True):\n    core_mask = np.zeros_like(dbscan.labels_, dtype=bool)\n    core_mask[dbscan.core_sample_indices_] = True\n    anomalies_mask = dbscan.labels_ == -1\n    non_core_mask = ~(core_mask | anomalies_mask)\n\n    cores = dbscan.components_\n    anomalies = X[anomalies_mask]\n    non_cores = X[non_core_mask]\n    \n    plt.scatter(cores[:, 0], cores[:, 1],\n                c=dbscan.labels_[core_mask], marker='o', s=size, cmap=\"Paired\")\n    plt.scatter(cores[:, 0], cores[:, 1], marker='*', s=20,\n                c=dbscan.labels_[core_mask])\n    plt.scatter(anomalies[:, 0], anomalies[:, 1],\n                c=\"r\", marker=\"x\", s=100)\n    plt.scatter(non_cores[:, 0], non_cores[:, 1],\n                c=dbscan.labels_[non_core_mask], marker=\".\")\n    if show_xlabels:\n        plt.xlabel(\"$x_1$\")\n    else:\n        plt.tick_params(labelbottom=False)\n    if show_ylabels:\n        plt.ylabel(\"$x_2$\", rotation=0)\n    else:\n        plt.tick_params(labelleft=False)\n    plt.title(f\"eps={dbscan.eps:.2f}, min_samples={dbscan.min_samples}\")\n    plt.grid()\n    plt.gca().set_axisbelow(True)\n\n# Create a dataset of two semicircles\nX, y = make_moons(n_samples = 1000, random_state = RANDOM_STATE)\n\n# Create 10 outlier points\nnp.random.seed(RANDOM_STATE)\nX_outliers = np.random.uniform(low = -6, high = 6, size = (40, 2))\nX = np.concatenate([X, X_outliers], axis = 0)\n\n# Initialize the DBSCAN clustering algorithm\ndb = DBSCAN(eps = 0.3)\n\n# Fit the data\ndb.fit(X)\n\n# Store the labels in a more readable field\nlabels = db.labels_\n\n# Print the estimated number of clusters and noise points\nprint(f\"Estimated number of clusters: {len(set(labels)) - (1 if -1 in labels else 0)}\")\nprint(f\"Estimated number of noise points: {list(labels).count(-1)}\")\n\n# Plot the data\nplot_dbscan(db, X, size = 500)\n\nEstimated number of clusters: 2\nEstimated number of noise points: 39\n\n\n\n\n\n\n\n\nHere we use the DBSCAN clustering algorithm to cluster a dataset of two semicircles. We set the eps to 0.3, and fit the data. We add several outlier points to the data to see if the DBSCAN algorithm can detect them. We then print the estimated number of clusters and noise points. We can see that the estimated number of clusters is 2, and the estimated number of noise points is 39. We added 40 points, which means that one of the randomly placed points on the graph was not detected as an outlier, and was close enough to one of the half moon clusters. We set the RANDOM_STATE to 20 for consistency and reproducibility. We print out the estimated number of clusters and noise points, and then plot the data."
  },
  {
    "objectID": "part5.html#anomalyoutlier-detection",
    "href": "part5.html#anomalyoutlier-detection",
    "title": "Part 5",
    "section": "",
    "text": "# Imports\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.datasets import make_moons\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nRANDOM_STATE = 20\n\n# Helper method that plots the clusters generated by DBSCAN from \n# handson-ml3 in 09_unsupervised_learning.ipynb\ndef plot_dbscan(dbscan, X, size, show_xlabels=True, show_ylabels=True):\n    core_mask = np.zeros_like(dbscan.labels_, dtype=bool)\n    core_mask[dbscan.core_sample_indices_] = True\n    anomalies_mask = dbscan.labels_ == -1\n    non_core_mask = ~(core_mask | anomalies_mask)\n\n    cores = dbscan.components_\n    anomalies = X[anomalies_mask]\n    non_cores = X[non_core_mask]\n    \n    plt.scatter(cores[:, 0], cores[:, 1],\n                c=dbscan.labels_[core_mask], marker='o', s=size, cmap=\"Paired\")\n    plt.scatter(cores[:, 0], cores[:, 1], marker='*', s=20,\n                c=dbscan.labels_[core_mask])\n    plt.scatter(anomalies[:, 0], anomalies[:, 1],\n                c=\"r\", marker=\"x\", s=100)\n    plt.scatter(non_cores[:, 0], non_cores[:, 1],\n                c=dbscan.labels_[non_core_mask], marker=\".\")\n    if show_xlabels:\n        plt.xlabel(\"$x_1$\")\n    else:\n        plt.tick_params(labelbottom=False)\n    if show_ylabels:\n        plt.ylabel(\"$x_2$\", rotation=0)\n    else:\n        plt.tick_params(labelleft=False)\n    plt.title(f\"eps={dbscan.eps:.2f}, min_samples={dbscan.min_samples}\")\n    plt.grid()\n    plt.gca().set_axisbelow(True)\n\n# Create a dataset of two semicircles\nX, y = make_moons(n_samples = 1000, random_state = RANDOM_STATE)\n\n# Create 10 outlier points\nnp.random.seed(RANDOM_STATE)\nX_outliers = np.random.uniform(low = -6, high = 6, size = (40, 2))\nX = np.concatenate([X, X_outliers], axis = 0)\n\n# Initialize the DBSCAN clustering algorithm\ndb = DBSCAN(eps = 0.3)\n\n# Fit the data\ndb.fit(X)\n\n# Store the labels in a more readable field\nlabels = db.labels_\n\n# Print the estimated number of clusters and noise points\nprint(f\"Estimated number of clusters: {len(set(labels)) - (1 if -1 in labels else 0)}\")\nprint(f\"Estimated number of noise points: {list(labels).count(-1)}\")\n\n# Plot the data\nplot_dbscan(db, X, size = 500)\n\nEstimated number of clusters: 2\nEstimated number of noise points: 39\n\n\n\n\n\n\n\n\nHere we use the DBSCAN clustering algorithm to cluster a dataset of two semicircles. We set the eps to 0.3, and fit the data. We add several outlier points to the data to see if the DBSCAN algorithm can detect them. We then print the estimated number of clusters and noise points. We can see that the estimated number of clusters is 2, and the estimated number of noise points is 39. We added 40 points, which means that one of the randomly placed points on the graph was not detected as an outlier, and was close enough to one of the half moon clusters. We set the RANDOM_STATE to 20 for consistency and reproducibility. We print out the estimated number of clusters and noise points, and then plot the data."
  },
  {
    "objectID": "part3.html",
    "href": "part3.html",
    "title": "Part 3",
    "section": "",
    "text": "# Imports\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.set_printoptions(precision = 10)\n\n# Constants for test size, and random state\nTEST_SIZE = 0.2\nRANDOM_STATE = 20\n\n# Set the random seed\nnp.random.seed(RANDOM_STATE)\n\n# Create a dataset of 500 points between -2pi and 2pi and their sin values\nX = np.random.uniform(-2 * np.pi, 2 * np.pi, size = (500, 1))\ny = np.sin(X)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, \n                                                    y, \n                                                    test_size = TEST_SIZE, \n                                                    shuffle = True, \n                                                    random_state = RANDOM_STATE)\n\n# Sort the test data\nindices = np.argsort(X_test, axis = 0)\nX_test_sorted = X_test[indices].ravel()\n\n# Create a figure to plot the data\nfigure = plt.figure(figsize = (12, 12))\nfigure.suptitle(\"Graphing Linear and Polynomial Regression Models for a \\\n                 Sin Function with Different Degrees\")\n\n# Plot the linear regression model for each degree between 1 and 9\nfor degree in range(1, 10):\n    \n    # Create a linear regression model and a polynomial features model\n    regr = LinearRegression()\n    poly = PolynomialFeatures(degree = degree)\n\n    # Fit the regression model to the training data\n    X_poly = poly.fit_transform(X_train)\n\n    # Fit the polynomial features model to the training data\n    regr.fit(X_poly, y_train)\n\n    # Transform the test data\n    X_test_poly = poly.transform(X_test)\n\n    # Predict the test data\n    y_pred = regr.predict(X_test_poly)\n\n    # Sort the predicted data\n    regr_y_pred = y_pred[indices].ravel()\n\n    # Plot the data\n    ax = figure.add_subplot(3, 3, degree)\n    ax.set_title(f\"{degree} Degree(s)\")\n    ax.scatter(X, y, label = \"Original Data\", s = 10, color = \"blue\")\n    ax.plot(X_test_sorted, \n            regr_y_pred, \n            label = f\"{degree} Degree Polynomial Regression Model\", \n            color = \"red\", \n            linewidth = 2)\n\n\n\n\n\n\n\nHere we use a linear regression model to predict the sin function. We create a dataset of 500 points between -2pi and 2pi and their sin values. We then split the data into training and testing sets. We then sort the test data to print a nice line graph. We then create a figure to plot the data. We then plot the linear regression model for each degree between 1 and 9. We set the RANDOM_STATE to 20 for consistency and reproducibility. We can see that the higher the degree, the more accurate the model is."
  },
  {
    "objectID": "part3.html#linear-and-nonlinear-regression",
    "href": "part3.html#linear-and-nonlinear-regression",
    "title": "Part 3",
    "section": "",
    "text": "# Imports\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.set_printoptions(precision = 10)\n\n# Constants for test size, and random state\nTEST_SIZE = 0.2\nRANDOM_STATE = 20\n\n# Set the random seed\nnp.random.seed(RANDOM_STATE)\n\n# Create a dataset of 500 points between -2pi and 2pi and their sin values\nX = np.random.uniform(-2 * np.pi, 2 * np.pi, size = (500, 1))\ny = np.sin(X)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, \n                                                    y, \n                                                    test_size = TEST_SIZE, \n                                                    shuffle = True, \n                                                    random_state = RANDOM_STATE)\n\n# Sort the test data\nindices = np.argsort(X_test, axis = 0)\nX_test_sorted = X_test[indices].ravel()\n\n# Create a figure to plot the data\nfigure = plt.figure(figsize = (12, 12))\nfigure.suptitle(\"Graphing Linear and Polynomial Regression Models for a \\\n                 Sin Function with Different Degrees\")\n\n# Plot the linear regression model for each degree between 1 and 9\nfor degree in range(1, 10):\n    \n    # Create a linear regression model and a polynomial features model\n    regr = LinearRegression()\n    poly = PolynomialFeatures(degree = degree)\n\n    # Fit the regression model to the training data\n    X_poly = poly.fit_transform(X_train)\n\n    # Fit the polynomial features model to the training data\n    regr.fit(X_poly, y_train)\n\n    # Transform the test data\n    X_test_poly = poly.transform(X_test)\n\n    # Predict the test data\n    y_pred = regr.predict(X_test_poly)\n\n    # Sort the predicted data\n    regr_y_pred = y_pred[indices].ravel()\n\n    # Plot the data\n    ax = figure.add_subplot(3, 3, degree)\n    ax.set_title(f\"{degree} Degree(s)\")\n    ax.scatter(X, y, label = \"Original Data\", s = 10, color = \"blue\")\n    ax.plot(X_test_sorted, \n            regr_y_pred, \n            label = f\"{degree} Degree Polynomial Regression Model\", \n            color = \"red\", \n            linewidth = 2)\n\n\n\n\n\n\n\nHere we use a linear regression model to predict the sin function. We create a dataset of 500 points between -2pi and 2pi and their sin values. We then split the data into training and testing sets. We then sort the test data to print a nice line graph. We then create a figure to plot the data. We then plot the linear regression model for each degree between 1 and 9. We set the RANDOM_STATE to 20 for consistency and reproducibility. We can see that the higher the degree, the more accurate the model is."
  },
  {
    "objectID": "part1.html",
    "href": "part1.html",
    "title": "Part 1",
    "section": "",
    "text": "# Imports\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import load_digits\nfrom sklearn.metrics import accuracy_score, precision_score, f1_score\nfrom sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n\n# Constants for random state of the splitting data, and test size as a percentage\nRANDOM_STATE = 20\nTEST_SIZE = 0.2\n\n# Load the data into data, and target variables separately\nX, y = load_digits(return_X_y = True)\n\n# Split the data using train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size = TEST_SIZE, \n                                                    shuffle = True, \n                                                    random_state = RANDOM_STATE)\n\n# Instantiate a Naive Bayes Gaussian Classifier\nclf = GaussianNB()\n\n# Fit the clasifier to the training data\nclf.fit(X_train, y_train)\n\n# Predict the test data\ny_pred = clf.predict(X_test)\n\n# Print the accuracy\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\nprint(f\"Precision: {precision_score(y_test, y_pred, average = 'weighted')}\")\nprint(f\"F1 Score: {f1_score(y_test, y_pred, average = 'weighted')}\")\n\nprint(f\"First 20 Elements of True Target Data:      {y_test[:20]}\")\nprint(f\"First 20 Elements of Predicted Target Data: {y_pred[:20]}\")\n\n# Create the confusion matrix\ncm = confusion_matrix(y_test, y_pred, labels = clf.classes_)\n\n# Plot the confusion matrix\ndisp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = clf.classes_)\ndisp.plot()\ndisp.ax_.set_title(\"Confusion Matrix for Digit Classification\");\n\nAccuracy: 0.8861111111111111\nPrecision: 0.9003197937062434\nF1 Score: 0.8855893653343448\nFirst 20 Elements of True Target Data:      [0 7 9 5 8 1 3 3 7 0 9 4 7 4 0 1 1 8 1 3]\nFirst 20 Elements of Predicted Target Data: [0 7 7 5 8 1 3 3 7 0 9 4 7 4 0 1 1 8 6 3]\n\n\n\n\n\n\n\n\nHere we use a Naive Byaes Model to classify handwritten digits. We split the data into training and testing sets, and then fit the model to the training data. We then predict the test data, and print the accuracy, precision, and F1 score. We also print the first 20 elements of the true target data, and the first 20 elements of the predicted target data. Finally, we plot the confusion matrix. We set a RANDOM_STATE of 20 for consistency and reproducibility. The TEST_SIZE was 0.2 or 20%, while training data was 80%. From the data we can see that the model is fairly accurate with accuracy of 0.886, preciision of 0.900, and F1 score of 0.886. Printing out the first 20 elements, we can see that the true target data is correct in 19/20 cases. Based on the confusion matrix we can see that 7 was misclassified as 4, a total of 6 times, and 2 was misclassified as 8 a total of 4 times, but otherwise the model is fairly accurate with all other numbers being misclassified 4 or fewer times."
  },
  {
    "objectID": "part1.html#probability-theory-and-random-variables",
    "href": "part1.html#probability-theory-and-random-variables",
    "title": "Part 1",
    "section": "",
    "text": "# Imports\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import load_digits\nfrom sklearn.metrics import accuracy_score, precision_score, f1_score\nfrom sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n\n# Constants for random state of the splitting data, and test size as a percentage\nRANDOM_STATE = 20\nTEST_SIZE = 0.2\n\n# Load the data into data, and target variables separately\nX, y = load_digits(return_X_y = True)\n\n# Split the data using train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size = TEST_SIZE, \n                                                    shuffle = True, \n                                                    random_state = RANDOM_STATE)\n\n# Instantiate a Naive Bayes Gaussian Classifier\nclf = GaussianNB()\n\n# Fit the clasifier to the training data\nclf.fit(X_train, y_train)\n\n# Predict the test data\ny_pred = clf.predict(X_test)\n\n# Print the accuracy\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\nprint(f\"Precision: {precision_score(y_test, y_pred, average = 'weighted')}\")\nprint(f\"F1 Score: {f1_score(y_test, y_pred, average = 'weighted')}\")\n\nprint(f\"First 20 Elements of True Target Data:      {y_test[:20]}\")\nprint(f\"First 20 Elements of Predicted Target Data: {y_pred[:20]}\")\n\n# Create the confusion matrix\ncm = confusion_matrix(y_test, y_pred, labels = clf.classes_)\n\n# Plot the confusion matrix\ndisp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = clf.classes_)\ndisp.plot()\ndisp.ax_.set_title(\"Confusion Matrix for Digit Classification\");\n\nAccuracy: 0.8861111111111111\nPrecision: 0.9003197937062434\nF1 Score: 0.8855893653343448\nFirst 20 Elements of True Target Data:      [0 7 9 5 8 1 3 3 7 0 9 4 7 4 0 1 1 8 1 3]\nFirst 20 Elements of Predicted Target Data: [0 7 7 5 8 1 3 3 7 0 9 4 7 4 0 1 1 8 6 3]\n\n\n\n\n\n\n\n\nHere we use a Naive Byaes Model to classify handwritten digits. We split the data into training and testing sets, and then fit the model to the training data. We then predict the test data, and print the accuracy, precision, and F1 score. We also print the first 20 elements of the true target data, and the first 20 elements of the predicted target data. Finally, we plot the confusion matrix. We set a RANDOM_STATE of 20 for consistency and reproducibility. The TEST_SIZE was 0.2 or 20%, while training data was 80%. From the data we can see that the model is fairly accurate with accuracy of 0.886, preciision of 0.900, and F1 score of 0.886. Printing out the first 20 elements, we can see that the true target data is correct in 19/20 cases. Based on the confusion matrix we can see that 7 was misclassified as 4, a total of 6 times, and 2 was misclassified as 8 a total of 4 times, but otherwise the model is fairly accurate with all other numbers being misclassified 4 or fewer times."
  },
  {
    "objectID": "final.html",
    "href": "final.html",
    "title": "CS 5805 Final Project",
    "section": "",
    "text": "Use the navigation buttons at the top of the page to navigate the blog."
  },
  {
    "objectID": "part2.html",
    "href": "part2.html",
    "title": "Part 2",
    "section": "",
    "text": "# Imports\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.datasets import make_moons\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Helper method that plots the clusters generated by DBSCAN from \n# handson-ml3 in 09_unsupervised_learning.ipynb\ndef plot_dbscan(dbscan, X, size, show_xlabels=True, show_ylabels=True):\n    core_mask = np.zeros_like(dbscan.labels_, dtype=bool)\n    core_mask[dbscan.core_sample_indices_] = True\n    anomalies_mask = dbscan.labels_ == -1\n    non_core_mask = ~(core_mask | anomalies_mask)\n\n    cores = dbscan.components_\n    anomalies = X[anomalies_mask]\n    non_cores = X[non_core_mask]\n    \n    plt.scatter(cores[:, 0], cores[:, 1],\n                c=dbscan.labels_[core_mask], marker='o', s=size, cmap=\"Paired\")\n    plt.scatter(cores[:, 0], cores[:, 1], marker='*', s=20,\n                c=dbscan.labels_[core_mask])\n    plt.scatter(anomalies[:, 0], anomalies[:, 1],\n                c=\"r\", marker=\"x\", s=100)\n    plt.scatter(non_cores[:, 0], non_cores[:, 1],\n                c=dbscan.labels_[non_core_mask], marker=\".\")\n    if show_xlabels:\n        plt.xlabel(\"$x_1$\")\n    else:\n        plt.tick_params(labelbottom=False)\n    if show_ylabels:\n        plt.ylabel(\"$x_2$\", rotation=0)\n    else:\n        plt.tick_params(labelleft=False)\n    plt.title(f\"eps={dbscan.eps:.2f}, min_samples={dbscan.min_samples}\")\n    plt.grid()\n    plt.gca().set_axisbelow(True)\n\n# Create a dataset of two semicircles\nX, y = make_moons(n_samples = 500)\n\n# Initialize the DBSCAN clustering algorithm\ndb = DBSCAN(eps = 0.3)\n\n# Fit the data\ndb.fit(X)\n\n# Store the labels in a more readable field\nlabels = db.labels_\n\n# Print the estimated number of clusters and noise points\nprint(f\"Estimated number of clusters: {len(set(labels)) - (1 if -1 in labels else 0)}\")\nprint(f\"Estimated number of noise points: {list(labels).count(-1)}\")\n\n# Plot the data\nplot_dbscan(db, X, size = 500)\n\nEstimated number of clusters: 2\nEstimated number of noise points: 0\n\n\n\n\n\n\n\n\nHere we use the DBSCAN clustering algorithm to cluster a dataset of two semicircles. We set the eps to 0.3, and fit the data. We then print the estimated number of clusters and noise points. We can see that the estimated number of clusters is 2, and the estimated number of noise points is 0. We can see that the clusters are very accurate, with no noise points. We set the RANDOM_STATE to 20 for consistency and reproducibility. We print out the estimated number of clusters and noise points, and then plot the data."
  },
  {
    "objectID": "part2.html#clustering",
    "href": "part2.html#clustering",
    "title": "Part 2",
    "section": "",
    "text": "# Imports\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.datasets import make_moons\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Helper method that plots the clusters generated by DBSCAN from \n# handson-ml3 in 09_unsupervised_learning.ipynb\ndef plot_dbscan(dbscan, X, size, show_xlabels=True, show_ylabels=True):\n    core_mask = np.zeros_like(dbscan.labels_, dtype=bool)\n    core_mask[dbscan.core_sample_indices_] = True\n    anomalies_mask = dbscan.labels_ == -1\n    non_core_mask = ~(core_mask | anomalies_mask)\n\n    cores = dbscan.components_\n    anomalies = X[anomalies_mask]\n    non_cores = X[non_core_mask]\n    \n    plt.scatter(cores[:, 0], cores[:, 1],\n                c=dbscan.labels_[core_mask], marker='o', s=size, cmap=\"Paired\")\n    plt.scatter(cores[:, 0], cores[:, 1], marker='*', s=20,\n                c=dbscan.labels_[core_mask])\n    plt.scatter(anomalies[:, 0], anomalies[:, 1],\n                c=\"r\", marker=\"x\", s=100)\n    plt.scatter(non_cores[:, 0], non_cores[:, 1],\n                c=dbscan.labels_[non_core_mask], marker=\".\")\n    if show_xlabels:\n        plt.xlabel(\"$x_1$\")\n    else:\n        plt.tick_params(labelbottom=False)\n    if show_ylabels:\n        plt.ylabel(\"$x_2$\", rotation=0)\n    else:\n        plt.tick_params(labelleft=False)\n    plt.title(f\"eps={dbscan.eps:.2f}, min_samples={dbscan.min_samples}\")\n    plt.grid()\n    plt.gca().set_axisbelow(True)\n\n# Create a dataset of two semicircles\nX, y = make_moons(n_samples = 500)\n\n# Initialize the DBSCAN clustering algorithm\ndb = DBSCAN(eps = 0.3)\n\n# Fit the data\ndb.fit(X)\n\n# Store the labels in a more readable field\nlabels = db.labels_\n\n# Print the estimated number of clusters and noise points\nprint(f\"Estimated number of clusters: {len(set(labels)) - (1 if -1 in labels else 0)}\")\nprint(f\"Estimated number of noise points: {list(labels).count(-1)}\")\n\n# Plot the data\nplot_dbscan(db, X, size = 500)\n\nEstimated number of clusters: 2\nEstimated number of noise points: 0\n\n\n\n\n\n\n\n\nHere we use the DBSCAN clustering algorithm to cluster a dataset of two semicircles. We set the eps to 0.3, and fit the data. We then print the estimated number of clusters and noise points. We can see that the estimated number of clusters is 2, and the estimated number of noise points is 0. We can see that the clusters are very accurate, with no noise points. We set the RANDOM_STATE to 20 for consistency and reproducibility. We print out the estimated number of clusters and noise points, and then plot the data."
  },
  {
    "objectID": "part4.html",
    "href": "part4.html",
    "title": "Part 4",
    "section": "",
    "text": "# Imports\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, precision_recall_curve, confusion_matrix\nfrom sklearn.metrics import ConfusionMatrixDisplay, PrecisionRecallDisplay\nfrom sklearn.metrics import RocCurveDisplay\nimport matplotlib.pyplot as plt\n\n# Constants for test size, and random state\nTEST_SIZE = 0.2\nRANDOM_STATE = 20\n\n# Instantiate the classifiers\nclassifiers = [DecisionTreeClassifier(), \n               KNeighborsClassifier(), \n               RandomForestClassifier()]\n\n# Load the data\nX, y = load_breast_cancer(return_X_y = True)\n\n# Split the data\nX_test, X_train, y_test, y_train = train_test_split(X, \n                                                    y, \n                                                    test_size = TEST_SIZE, \n                                                    shuffle = True, \n                                                    random_state = RANDOM_STATE)\n\nfigure = plt.figure(figsize = (15, 15))\n\n# Iterate through the classifiers\nfor idx, clf in enumerate(classifiers):\n\n    idx += 1\n\n    # Get the name of the classifier\n    name = clf.__class__.__name__\n\n    # Fit the classifier to the training data\n    clf.fit(X_train, y_train)\n\n    # Predict the test data\n    y_pred = clf.predict(X_test)\n\n    # Calculate info about the ROC Curve, Precision Recall Curve, and Confusion Matrix\n    precision, recall, thresholds = precision_recall_curve(y_test, y_pred)\n    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n    cm = confusion_matrix(y_test, y_pred, labels = clf.classes_)\n\n    # Create the displays\n    precision_recall_curve_display = PrecisionRecallDisplay(precision = precision, \n                                                            recall = recall)\n    roc_curve_display = RocCurveDisplay(fpr = fpr, tpr = tpr)\n    confusion_matrix_display = ConfusionMatrixDisplay(confusion_matrix = cm, \n                                                      display_labels = clf.classes_)\n\n    # Plot the ROC and Precision Recall Curves\n    ax1 = figure.add_subplot(3, 3, idx)\n    ax1.set_title(f\"{name} PR Curve\")\n    precision_recall_curve_display.plot(ax = ax1, label = \"Precision Recall Curve\")\n    ax1.legend_.remove()\n\n    ax2 = figure.add_subplot(3, 3, idx + len(classifiers))\n    ax2.set_title(f\"{name} ROC Curve\")\n    roc_curve_display.plot(ax = ax2, label = \"ROC Curve\")\n    ax2.legend_.remove()\n\n    # Plot the confusion matrix\n    ax3 = figure.add_subplot(3, 3, idx + 2 * len(classifiers))\n    ax3.set_title(f\"{name} Confusion Matrix\", fontsize = 10)\n    confusion_matrix_display.plot(ax = ax3)\n\n\n\n\n\n\n\nHere we use three different classifiers to classify breast cancer data. We use a Decision Tree Classifier, a K Neighbors Classifier, and a Random Forest Classifier. We split the data into training and testing sets. We then fit the classifiers to the training data, and predict the test data. We then calculate info about the ROC Curve, Precision Recall Curve, and Confusion Matrix. We then create the displays for the ROC and Precision Recall Curves, and the Confusion Matrix. We set the RANDOM_STATE to 20 for consistency and reproducibility. We can see that the Random Forest Classifier is the most accurate, with the highest precision and recall, and the highest area under the ROC curve. The K Neighbors Classifier is the least accurate, with the most false positives and false negatives in the confusion matrix. The Decision Tree Classifier had the most false misclassification of the 1 class, with 30 false negatives."
  },
  {
    "objectID": "part4.html#classification",
    "href": "part4.html#classification",
    "title": "Part 4",
    "section": "",
    "text": "# Imports\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, precision_recall_curve, confusion_matrix\nfrom sklearn.metrics import ConfusionMatrixDisplay, PrecisionRecallDisplay\nfrom sklearn.metrics import RocCurveDisplay\nimport matplotlib.pyplot as plt\n\n# Constants for test size, and random state\nTEST_SIZE = 0.2\nRANDOM_STATE = 20\n\n# Instantiate the classifiers\nclassifiers = [DecisionTreeClassifier(), \n               KNeighborsClassifier(), \n               RandomForestClassifier()]\n\n# Load the data\nX, y = load_breast_cancer(return_X_y = True)\n\n# Split the data\nX_test, X_train, y_test, y_train = train_test_split(X, \n                                                    y, \n                                                    test_size = TEST_SIZE, \n                                                    shuffle = True, \n                                                    random_state = RANDOM_STATE)\n\nfigure = plt.figure(figsize = (15, 15))\n\n# Iterate through the classifiers\nfor idx, clf in enumerate(classifiers):\n\n    idx += 1\n\n    # Get the name of the classifier\n    name = clf.__class__.__name__\n\n    # Fit the classifier to the training data\n    clf.fit(X_train, y_train)\n\n    # Predict the test data\n    y_pred = clf.predict(X_test)\n\n    # Calculate info about the ROC Curve, Precision Recall Curve, and Confusion Matrix\n    precision, recall, thresholds = precision_recall_curve(y_test, y_pred)\n    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n    cm = confusion_matrix(y_test, y_pred, labels = clf.classes_)\n\n    # Create the displays\n    precision_recall_curve_display = PrecisionRecallDisplay(precision = precision, \n                                                            recall = recall)\n    roc_curve_display = RocCurveDisplay(fpr = fpr, tpr = tpr)\n    confusion_matrix_display = ConfusionMatrixDisplay(confusion_matrix = cm, \n                                                      display_labels = clf.classes_)\n\n    # Plot the ROC and Precision Recall Curves\n    ax1 = figure.add_subplot(3, 3, idx)\n    ax1.set_title(f\"{name} PR Curve\")\n    precision_recall_curve_display.plot(ax = ax1, label = \"Precision Recall Curve\")\n    ax1.legend_.remove()\n\n    ax2 = figure.add_subplot(3, 3, idx + len(classifiers))\n    ax2.set_title(f\"{name} ROC Curve\")\n    roc_curve_display.plot(ax = ax2, label = \"ROC Curve\")\n    ax2.legend_.remove()\n\n    # Plot the confusion matrix\n    ax3 = figure.add_subplot(3, 3, idx + 2 * len(classifiers))\n    ax3.set_title(f\"{name} Confusion Matrix\", fontsize = 10)\n    confusion_matrix_display.plot(ax = ax3)\n\n\n\n\n\n\n\nHere we use three different classifiers to classify breast cancer data. We use a Decision Tree Classifier, a K Neighbors Classifier, and a Random Forest Classifier. We split the data into training and testing sets. We then fit the classifiers to the training data, and predict the test data. We then calculate info about the ROC Curve, Precision Recall Curve, and Confusion Matrix. We then create the displays for the ROC and Precision Recall Curves, and the Confusion Matrix. We set the RANDOM_STATE to 20 for consistency and reproducibility. We can see that the Random Forest Classifier is the most accurate, with the highest precision and recall, and the highest area under the ROC curve. The K Neighbors Classifier is the least accurate, with the most false positives and false negatives in the confusion matrix. The Decision Tree Classifier had the most false misclassification of the 1 class, with 30 false negatives."
  }
]