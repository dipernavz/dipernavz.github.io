<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Vincent DiPerna">
<meta name="dcterms.date" content="2023-11-27">

<title>CS 5805 Final Project</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body>

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#part-1-probability-theory-and-random-variables" id="toc-part-1-probability-theory-and-random-variables" class="nav-link active" data-scroll-target="#part-1-probability-theory-and-random-variables">Part 1: Probability Theory and Random Variables</a>
  <ul class="collapse">
  <li><a href="#code" id="toc-code" class="nav-link" data-scroll-target="#code">Code</a></li>
  <li><a href="#explanation" id="toc-explanation" class="nav-link" data-scroll-target="#explanation">Explanation</a></li>
  </ul></li>
  <li><a href="#part-2-clustering" id="toc-part-2-clustering" class="nav-link" data-scroll-target="#part-2-clustering">Part 2: Clustering</a>
  <ul class="collapse">
  <li><a href="#code-1" id="toc-code-1" class="nav-link" data-scroll-target="#code-1">Code</a></li>
  <li><a href="#explanation-1" id="toc-explanation-1" class="nav-link" data-scroll-target="#explanation-1">Explanation</a></li>
  </ul></li>
  <li><a href="#part-3-linear-and-nonlinear-regression" id="toc-part-3-linear-and-nonlinear-regression" class="nav-link" data-scroll-target="#part-3-linear-and-nonlinear-regression">Part 3: Linear and Nonlinear Regression</a>
  <ul class="collapse">
  <li><a href="#code-2" id="toc-code-2" class="nav-link" data-scroll-target="#code-2">Code</a></li>
  <li><a href="#explanation-2" id="toc-explanation-2" class="nav-link" data-scroll-target="#explanation-2">Explanation</a></li>
  </ul></li>
  <li><a href="#part-4-classification" id="toc-part-4-classification" class="nav-link" data-scroll-target="#part-4-classification">Part 4: Classification</a>
  <ul class="collapse">
  <li><a href="#code-3" id="toc-code-3" class="nav-link" data-scroll-target="#code-3">Code</a></li>
  <li><a href="#explanation-3" id="toc-explanation-3" class="nav-link" data-scroll-target="#explanation-3">Explanation</a></li>
  </ul></li>
  <li><a href="#part-5-anomalyoutlier-detection" id="toc-part-5-anomalyoutlier-detection" class="nav-link" data-scroll-target="#part-5-anomalyoutlier-detection">Part 5: Anomaly/Outlier Detection</a>
  <ul class="collapse">
  <li><a href="#code-4" id="toc-code-4" class="nav-link" data-scroll-target="#code-4">Code</a></li>
  <li><a href="#explanation-4" id="toc-explanation-4" class="nav-link" data-scroll-target="#explanation-4">Explanation</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/dipernavz/dipernavz.github.io/blob/main/final.qmd" class="toc-action">View source</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">CS 5805 Final Project</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Vincent DiPerna </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">November 27, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<section id="part-1-probability-theory-and-random-variables" class="level2">
<h2 class="anchored" data-anchor-id="part-1-probability-theory-and-random-variables">Part 1: Probability Theory and Random Variables</h2>
<section id="code" class="level3">
<h3 class="anchored" data-anchor-id="code">Code</h3>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Imports</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> GaussianNB</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_digits</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, precision_score, f1_score</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> ConfusionMatrixDisplay, confusion_matrix</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Constants for random state of the splitting data, and test size as a percentage</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>RANDOM_STATE <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>TEST_SIZE <span class="op">=</span> <span class="fl">0.2</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the data into data, and target variables separately</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> load_digits(return_X_y <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data using train_test_split</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, </span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>                                                    test_size <span class="op">=</span> TEST_SIZE, </span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>                                                    shuffle <span class="op">=</span> <span class="va">True</span>, </span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>                                                    random_state <span class="op">=</span> RANDOM_STATE)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Instantiate a Naive Bayes Gaussian Classifier</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> GaussianNB()</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the clasifier to the training data</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>clf.fit(X_train, y_train)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict the test data</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> clf.predict(X_test)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the accuracy</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy_score(y_test, y_pred)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Precision: </span><span class="sc">{</span>precision_score(y_test, y_pred, average <span class="op">=</span> <span class="st">'weighted'</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"F1 Score: </span><span class="sc">{</span>f1_score(y_test, y_pred, average <span class="op">=</span> <span class="st">'weighted'</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"First 20 Elements of True Target Data:      </span><span class="sc">{</span>y_test[:<span class="dv">20</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"First 20 Elements of Predicted Target Data: </span><span class="sc">{</span>y_pred[:<span class="dv">20</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the confusion matrix</span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_test, y_pred, labels <span class="op">=</span> clf.classes_)</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the confusion matrix</span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>disp <span class="op">=</span> ConfusionMatrixDisplay(confusion_matrix <span class="op">=</span> cm, display_labels <span class="op">=</span> clf.classes_)</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>disp.plot()</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>disp.ax_.set_title(<span class="st">"Confusion Matrix for Digit Classification"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.8861111111111111
Precision: 0.9003197937062434
F1 Score: 0.8855893653343448
First 20 Elements of True Target Data:      [0 7 9 5 8 1 3 3 7 0 9 4 7 4 0 1 1 8 1 3]
First 20 Elements of Predicted Target Data: [0 7 7 5 8 1 3 3 7 0 9 4 7 4 0 1 1 8 6 3]</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="final_files/figure-html/cell-2-output-2.png" width="496" height="449"></p>
</div>
</div>
</section>
<section id="explanation" class="level3">
<h3 class="anchored" data-anchor-id="explanation">Explanation</h3>
<p>Here we use a Naive Byaes Model to classify handwritten digits. We split the data into training and testing sets, and then fit the model to the training data. We then predict the test data, and print the accuracy, precision, and F1 score. We also print the first 20 elements of the true target data, and the first 20 elements of the predicted target data. Finally, we plot the confusion matrix. We set a RANDOM_STATE of 20 for consistency and reproducibility. The TEST_SIZE was 0.2 or 20%, while training data was 80%. From the data we can see that the model is fairly accurate with accuracy of 0.886, preciision of 0.900, and F1 score of 0.886. Printing out the first 20 elements, we can see that the true target data is correct in 19/20 cases. Based on the confusion matrix we can see that 7 was misclassified as 4, a total of 6 times, and 2 was misclassified as 8 a total of 4 times, but otherwise the model is fairly accurate with all other numbers being misclassified 4 or fewer times.</p>
</section>
</section>
<section id="part-2-clustering" class="level2">
<h2 class="anchored" data-anchor-id="part-2-clustering">Part 2: Clustering</h2>
<section id="code-1" class="level3">
<h3 class="anchored" data-anchor-id="code-1">Code</h3>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Imports</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> DBSCAN</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_moons</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Helper method that plots the clusters generated by DBSCAN from </span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co"># handson-ml3 in 09_unsupervised_learning.ipynb</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_dbscan(dbscan, X, size, show_xlabels<span class="op">=</span><span class="va">True</span>, show_ylabels<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    core_mask <span class="op">=</span> np.zeros_like(dbscan.labels_, dtype<span class="op">=</span><span class="bu">bool</span>)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    core_mask[dbscan.core_sample_indices_] <span class="op">=</span> <span class="va">True</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    anomalies_mask <span class="op">=</span> dbscan.labels_ <span class="op">==</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    non_core_mask <span class="op">=</span> <span class="op">~</span>(core_mask <span class="op">|</span> anomalies_mask)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    cores <span class="op">=</span> dbscan.components_</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    anomalies <span class="op">=</span> X[anomalies_mask]</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    non_cores <span class="op">=</span> X[non_core_mask]</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    plt.scatter(cores[:, <span class="dv">0</span>], cores[:, <span class="dv">1</span>],</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>                c<span class="op">=</span>dbscan.labels_[core_mask], marker<span class="op">=</span><span class="st">'o'</span>, s<span class="op">=</span>size, cmap<span class="op">=</span><span class="st">"Paired"</span>)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>    plt.scatter(cores[:, <span class="dv">0</span>], cores[:, <span class="dv">1</span>], marker<span class="op">=</span><span class="st">'*'</span>, s<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>                c<span class="op">=</span>dbscan.labels_[core_mask])</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>    plt.scatter(anomalies[:, <span class="dv">0</span>], anomalies[:, <span class="dv">1</span>],</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>                c<span class="op">=</span><span class="st">"r"</span>, marker<span class="op">=</span><span class="st">"x"</span>, s<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>    plt.scatter(non_cores[:, <span class="dv">0</span>], non_cores[:, <span class="dv">1</span>],</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>                c<span class="op">=</span>dbscan.labels_[non_core_mask], marker<span class="op">=</span><span class="st">"."</span>)</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> show_xlabels:</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>        plt.xlabel(<span class="st">"$x_1$"</span>)</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>        plt.tick_params(labelbottom<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> show_ylabels:</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>        plt.ylabel(<span class="st">"$x_2$"</span>, rotation<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>        plt.tick_params(labelleft<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f"eps=</span><span class="sc">{</span>dbscan<span class="sc">.</span>eps<span class="sc">:.2f}</span><span class="ss">, min_samples=</span><span class="sc">{</span>dbscan<span class="sc">.</span>min_samples<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>    plt.grid()</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>    plt.gca().set_axisbelow(<span class="va">True</span>)</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a dataset of two semicircles</span></span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_moons(n_samples <span class="op">=</span> <span class="dv">500</span>)</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the DBSCAN clustering algorithm</span></span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>db <span class="op">=</span> DBSCAN(eps <span class="op">=</span> <span class="fl">0.3</span>)</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the data</span></span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>db.fit(X)</span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Store the labels in a more readable field</span></span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> db.labels_</span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the estimated number of clusters and noise points</span></span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Estimated number of clusters: </span><span class="sc">{</span><span class="bu">len</span>(<span class="bu">set</span>(labels)) <span class="op">-</span> (<span class="dv">1</span> <span class="cf">if</span> <span class="op">-</span><span class="dv">1</span> <span class="kw">in</span> labels <span class="cf">else</span> <span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Estimated number of noise points: </span><span class="sc">{</span><span class="bu">list</span>(labels)<span class="sc">.</span>count(<span class="op">-</span><span class="dv">1</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the data</span></span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true" tabindex="-1"></a>plot_dbscan(db, X, size <span class="op">=</span> <span class="dv">500</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Estimated number of clusters: 2
Estimated number of noise points: 0</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="final_files/figure-html/cell-3-output-2.png" width="594" height="449"></p>
</div>
</div>
</section>
<section id="explanation-1" class="level3">
<h3 class="anchored" data-anchor-id="explanation-1">Explanation</h3>
<p>Here we use the DBSCAN clustering algorithm to cluster a dataset of two semicircles. We set the eps to 0.3, and fit the data. We then print the estimated number of clusters and noise points. We can see that the estimated number of clusters is 2, and the estimated number of noise points is 0. We can see that the clusters are very accurate, with no noise points. We set the RANDOM_STATE to 20 for consistency and reproducibility. We print out the estimated number of clusters and noise points, and then plot the data.</p>
</section>
</section>
<section id="part-3-linear-and-nonlinear-regression" class="level2">
<h2 class="anchored" data-anchor-id="part-3-linear-and-nonlinear-regression">Part 3: Linear and Nonlinear Regression</h2>
<section id="code-2" class="level3">
<h3 class="anchored" data-anchor-id="code-2">Code</h3>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Imports</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> PolynomialFeatures</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>np.set_printoptions(precision <span class="op">=</span> <span class="dv">10</span>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Constants for test size, and random state</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>TEST_SIZE <span class="op">=</span> <span class="fl">0.2</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>RANDOM_STATE <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the random seed</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>np.random.seed(RANDOM_STATE)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a dataset of 500 points between -2pi and 2pi and their sin values</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.random.uniform(<span class="op">-</span><span class="dv">2</span> <span class="op">*</span> np.pi, <span class="dv">2</span> <span class="op">*</span> np.pi, size <span class="op">=</span> (<span class="dv">500</span>, <span class="dv">1</span>))</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.sin(X)</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data into training and testing sets</span></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, </span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>                                                    y, </span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>                                                    test_size <span class="op">=</span> TEST_SIZE, </span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>                                                    shuffle <span class="op">=</span> <span class="va">True</span>, </span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>                                                    random_state <span class="op">=</span> RANDOM_STATE)</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Sort the test data</span></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>indices <span class="op">=</span> np.argsort(X_test, axis <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>X_test_sorted <span class="op">=</span> X_test[indices].ravel()</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a figure to plot the data</span></span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>figure <span class="op">=</span> plt.figure(figsize <span class="op">=</span> (<span class="dv">12</span>, <span class="dv">12</span>))</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>figure.suptitle(<span class="st">"Graphing Linear and Polynomial Regression Models for a </span><span class="ch">\</span></span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a><span class="st">                 Sin Function with Different Degrees"</span>)</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the linear regression model for each degree between 1 and 9</span></span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> degree <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">10</span>):</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a linear regression model and a polynomial features model</span></span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>    regr <span class="op">=</span> LinearRegression()</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>    poly <span class="op">=</span> PolynomialFeatures(degree <span class="op">=</span> degree)</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit the regression model to the training data</span></span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>    X_poly <span class="op">=</span> poly.fit_transform(X_train)</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit the polynomial features model to the training data</span></span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>    regr.fit(X_poly, y_train)</span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Transform the test data</span></span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>    X_test_poly <span class="op">=</span> poly.transform(X_test)</span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Predict the test data</span></span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> regr.predict(X_test_poly)</span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sort the predicted data</span></span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a>    regr_y_pred <span class="op">=</span> y_pred[indices].ravel()</span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot the data</span></span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> figure.add_subplot(<span class="dv">3</span>, <span class="dv">3</span>, degree)</span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f"</span><span class="sc">{</span>degree<span class="sc">}</span><span class="ss"> Degree(s)"</span>)</span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a>    ax.scatter(X, y, label <span class="op">=</span> <span class="st">"Original Data"</span>, s <span class="op">=</span> <span class="dv">10</span>, color <span class="op">=</span> <span class="st">"blue"</span>)</span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a>    ax.plot(X_test_sorted, </span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a>            regr_y_pred, </span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a>            label <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>degree<span class="sc">}</span><span class="ss"> Degree Polynomial Regression Model"</span>, </span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a>            color <span class="op">=</span> <span class="st">"red"</span>, </span>
<span id="cb5-67"><a href="#cb5-67" aria-hidden="true" tabindex="-1"></a>            linewidth <span class="op">=</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="final_files/figure-html/cell-4-output-1.png" width="962" height="1044"></p>
</div>
</div>
</section>
<section id="explanation-2" class="level3">
<h3 class="anchored" data-anchor-id="explanation-2">Explanation</h3>
<p>Here we use a linear regression model to predict the sin function. We create a dataset of 500 points between -2pi and 2pi and their sin values. We then split the data into training and testing sets. We then sort the test data to print a nice line graph. We then create a figure to plot the data. We then plot the linear regression model for each degree between 1 and 9. We set the RANDOM_STATE to 20 for consistency and reproducibility. We can see that the higher the degree, the more accurate the model is.</p>
</section>
</section>
<section id="part-4-classification" class="level2">
<h2 class="anchored" data-anchor-id="part-4-classification">Part 4: Classification</h2>
<section id="code-3" class="level3">
<h3 class="anchored" data-anchor-id="code-3">Code</h3>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Imports</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_breast_cancer</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_curve, precision_recall_curve, confusion_matrix</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> ConfusionMatrixDisplay, PrecisionRecallDisplay</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> RocCurveDisplay</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Instantiate the classifiers</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>classifiers <span class="op">=</span> [DecisionTreeClassifier(), </span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>               KNeighborsClassifier(), </span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>               RandomForestClassifier()]</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the data</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> load_breast_cancer(return_X_y <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>X_test, X_train, y_test, y_train <span class="op">=</span> train_test_split(X, </span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>                                                    y, </span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>                                                    test_size <span class="op">=</span> TEST_SIZE, </span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>                                                    shuffle <span class="op">=</span> <span class="va">True</span>, </span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>                                                    random_state <span class="op">=</span> RANDOM_STATE)</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>figure <span class="op">=</span> plt.figure(figsize <span class="op">=</span> (<span class="dv">15</span>, <span class="dv">15</span>))</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Iterate through the classifiers</span></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, clf <span class="kw">in</span> <span class="bu">enumerate</span>(classifiers):</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>    idx <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get the name of the classifier</span></span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>    name <span class="op">=</span> clf.__class__.<span class="va">__name__</span></span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit the classifier to the training data</span></span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>    clf.fit(X_train, y_train)</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Predict the test data</span></span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> clf.predict(X_test)</span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate info about the ROC Curve, Precision Recall Curve, and Confusion Matrix</span></span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>    precision, recall, thresholds <span class="op">=</span> precision_recall_curve(y_test, y_pred)</span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>    fpr, tpr, thresholds <span class="op">=</span> roc_curve(y_test, y_pred)</span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>    cm <span class="op">=</span> confusion_matrix(y_test, y_pred, labels <span class="op">=</span> clf.classes_)</span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create the displays</span></span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a>    precision_recall_curve_display <span class="op">=</span> PrecisionRecallDisplay(precision <span class="op">=</span> precision, </span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a>                                                            recall <span class="op">=</span> recall)</span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a>    roc_curve_display <span class="op">=</span> RocCurveDisplay(fpr <span class="op">=</span> fpr, tpr <span class="op">=</span> tpr)</span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a>    confusion_matrix_display <span class="op">=</span> ConfusionMatrixDisplay(confusion_matrix <span class="op">=</span> cm, </span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a>                                                      display_labels <span class="op">=</span> clf.classes_)</span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot the ROC and Precision Recall Curves</span></span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a>    ax1 <span class="op">=</span> figure.add_subplot(<span class="dv">3</span>, <span class="dv">3</span>, idx)</span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a>    ax1.set_title(<span class="ss">f"</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss"> PR Curve"</span>)</span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a>    precision_recall_curve_display.plot(ax <span class="op">=</span> ax1, label <span class="op">=</span> <span class="st">"Precision Recall Curve"</span>)</span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a>    ax1.legend_.remove()</span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a>    ax2 <span class="op">=</span> figure.add_subplot(<span class="dv">3</span>, <span class="dv">3</span>, idx <span class="op">+</span> <span class="bu">len</span>(classifiers))</span>
<span id="cb6-61"><a href="#cb6-61" aria-hidden="true" tabindex="-1"></a>    ax2.set_title(<span class="ss">f"</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss"> ROC Curve"</span>)</span>
<span id="cb6-62"><a href="#cb6-62" aria-hidden="true" tabindex="-1"></a>    roc_curve_display.plot(ax <span class="op">=</span> ax2, label <span class="op">=</span> <span class="st">"ROC Curve"</span>)</span>
<span id="cb6-63"><a href="#cb6-63" aria-hidden="true" tabindex="-1"></a>    ax2.legend_.remove()</span>
<span id="cb6-64"><a href="#cb6-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-65"><a href="#cb6-65" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot the confusion matrix</span></span>
<span id="cb6-66"><a href="#cb6-66" aria-hidden="true" tabindex="-1"></a>    ax3 <span class="op">=</span> figure.add_subplot(<span class="dv">3</span>, <span class="dv">3</span>, idx <span class="op">+</span> <span class="dv">2</span> <span class="op">*</span> <span class="bu">len</span>(classifiers))</span>
<span id="cb6-67"><a href="#cb6-67" aria-hidden="true" tabindex="-1"></a>    ax3.set_title(<span class="ss">f"</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss"> Confusion Matrix"</span>, fontsize <span class="op">=</span> <span class="dv">10</span>)</span>
<span id="cb6-68"><a href="#cb6-68" aria-hidden="true" tabindex="-1"></a>    confusion_matrix_display.plot(ax <span class="op">=</span> ax3)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="final_files/figure-html/cell-5-output-1.png" width="1194" height="1157"></p>
</div>
</div>
</section>
<section id="explanation-3" class="level3">
<h3 class="anchored" data-anchor-id="explanation-3">Explanation</h3>
<p>Here we use three different classifiers to classify breast cancer data. We use a Decision Tree Classifier, a K Neighbors Classifier, and a Random Forest Classifier. We split the data into training and testing sets. We then fit the classifiers to the training data, and predict the test data. We then calculate info about the ROC Curve, Precision Recall Curve, and Confusion Matrix. We then create the displays for the ROC and Precision Recall Curves, and the Confusion Matrix. We set the RANDOM_STATE to 20 for consistency and reproducibility. We can see that the Random Forest Classifier is the most accurate, with the highest precision and recall, and the highest area under the ROC curve. The K Neighbors Classifier is the least accurate, with the most false positives and false negatives in the confusion matrix. The Decision Tree Classifier had the most false misclassification of the 1 class, with 30 false negatives.</p>
</section>
</section>
<section id="part-5-anomalyoutlier-detection" class="level2">
<h2 class="anchored" data-anchor-id="part-5-anomalyoutlier-detection">Part 5: Anomaly/Outlier Detection</h2>
<section id="code-4" class="level3">
<h3 class="anchored" data-anchor-id="code-4">Code</h3>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Imports</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> DBSCAN</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_moons</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>RANDOM_STATE <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Helper method that plots the clusters generated by DBSCAN from </span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="co"># handson-ml3 in 09_unsupervised_learning.ipynb</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_dbscan(dbscan, X, size, show_xlabels<span class="op">=</span><span class="va">True</span>, show_ylabels<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    core_mask <span class="op">=</span> np.zeros_like(dbscan.labels_, dtype<span class="op">=</span><span class="bu">bool</span>)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    core_mask[dbscan.core_sample_indices_] <span class="op">=</span> <span class="va">True</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>    anomalies_mask <span class="op">=</span> dbscan.labels_ <span class="op">==</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    non_core_mask <span class="op">=</span> <span class="op">~</span>(core_mask <span class="op">|</span> anomalies_mask)</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>    cores <span class="op">=</span> dbscan.components_</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>    anomalies <span class="op">=</span> X[anomalies_mask]</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>    non_cores <span class="op">=</span> X[non_core_mask]</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>    plt.scatter(cores[:, <span class="dv">0</span>], cores[:, <span class="dv">1</span>],</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>                c<span class="op">=</span>dbscan.labels_[core_mask], marker<span class="op">=</span><span class="st">'o'</span>, s<span class="op">=</span>size, cmap<span class="op">=</span><span class="st">"Paired"</span>)</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>    plt.scatter(cores[:, <span class="dv">0</span>], cores[:, <span class="dv">1</span>], marker<span class="op">=</span><span class="st">'*'</span>, s<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>                c<span class="op">=</span>dbscan.labels_[core_mask])</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>    plt.scatter(anomalies[:, <span class="dv">0</span>], anomalies[:, <span class="dv">1</span>],</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>                c<span class="op">=</span><span class="st">"r"</span>, marker<span class="op">=</span><span class="st">"x"</span>, s<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>    plt.scatter(non_cores[:, <span class="dv">0</span>], non_cores[:, <span class="dv">1</span>],</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>                c<span class="op">=</span>dbscan.labels_[non_core_mask], marker<span class="op">=</span><span class="st">"."</span>)</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> show_xlabels:</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>        plt.xlabel(<span class="st">"$x_1$"</span>)</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>        plt.tick_params(labelbottom<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> show_ylabels:</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>        plt.ylabel(<span class="st">"$x_2$"</span>, rotation<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>        plt.tick_params(labelleft<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f"eps=</span><span class="sc">{</span>dbscan<span class="sc">.</span>eps<span class="sc">:.2f}</span><span class="ss">, min_samples=</span><span class="sc">{</span>dbscan<span class="sc">.</span>min_samples<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>    plt.grid()</span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>    plt.gca().set_axisbelow(<span class="va">True</span>)</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a dataset of two semicircles</span></span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_moons(n_samples <span class="op">=</span> <span class="dv">1000</span>, random_state <span class="op">=</span> RANDOM_STATE)</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Create 10 outlier points</span></span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>np.random.seed(RANDOM_STATE)</span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>X_outliers <span class="op">=</span> np.random.uniform(low <span class="op">=</span> <span class="op">-</span><span class="dv">6</span>, high <span class="op">=</span> <span class="dv">6</span>, size <span class="op">=</span> (<span class="dv">40</span>, <span class="dv">2</span>))</span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.concatenate([X, X_outliers], axis <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the DBSCAN clustering algorithm</span></span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>db <span class="op">=</span> DBSCAN(eps <span class="op">=</span> <span class="fl">0.3</span>)</span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the data</span></span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a>db.fit(X)</span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a><span class="co"># Store the labels in a more readable field</span></span>
<span id="cb7-56"><a href="#cb7-56" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> db.labels_</span>
<span id="cb7-57"><a href="#cb7-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-58"><a href="#cb7-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the estimated number of clusters and noise points</span></span>
<span id="cb7-59"><a href="#cb7-59" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Estimated number of clusters: </span><span class="sc">{</span><span class="bu">len</span>(<span class="bu">set</span>(labels)) <span class="op">-</span> (<span class="dv">1</span> <span class="cf">if</span> <span class="op">-</span><span class="dv">1</span> <span class="kw">in</span> labels <span class="cf">else</span> <span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-60"><a href="#cb7-60" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Estimated number of noise points: </span><span class="sc">{</span><span class="bu">list</span>(labels)<span class="sc">.</span>count(<span class="op">-</span><span class="dv">1</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-61"><a href="#cb7-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-62"><a href="#cb7-62" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the data</span></span>
<span id="cb7-63"><a href="#cb7-63" aria-hidden="true" tabindex="-1"></a>plot_dbscan(db, X, size <span class="op">=</span> <span class="dv">500</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Estimated number of clusters: 2
Estimated number of noise points: 39</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="final_files/figure-html/cell-6-output-2.png" width="581" height="449"></p>
</div>
</div>
</section>
<section id="explanation-4" class="level3">
<h3 class="anchored" data-anchor-id="explanation-4">Explanation</h3>
<p>Here we use the DBSCAN clustering algorithm to cluster a dataset of two semicircles. We set the eps to 0.3, and fit the data. We add several outlier points to the data to see if the DBSCAN algorithm can detect them. We then print the estimated number of clusters and noise points. We can see that the estimated number of clusters is 2, and the estimated number of noise points is 39. We added 40 points, which means that one of the randomly placed points on the graph was not detected as an outlier, and was close enough to one of the half moon clusters. We set the RANDOM_STATE to 20 for consistency and reproducibility. We print out the estimated number of clusters and noise points, and then plot the data.</p>


<!-- -->

</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb9" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "CS 5805 Final Project"</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2023-11-27"</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co">    - name: Vincent DiPerna</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co">    html:</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="co">        code-fold: false</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="co">        toc: true</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="an">jupyter:</span><span class="co"> python3</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="fu">## Part 1: Probability Theory and Random Variables</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a><span class="fu">### Code</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Imports</span></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> GaussianNB</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_digits</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, precision_score, f1_score</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> ConfusionMatrixDisplay, confusion_matrix</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Constants for random state of the splitting data, and test size as a percentage</span></span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>RANDOM_STATE <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>TEST_SIZE <span class="op">=</span> <span class="fl">0.2</span></span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the data into data, and target variables separately</span></span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> load_digits(return_X_y <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data using train_test_split</span></span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, </span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a>                                                    test_size <span class="op">=</span> TEST_SIZE, </span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a>                                                    shuffle <span class="op">=</span> <span class="va">True</span>, </span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a>                                                    random_state <span class="op">=</span> RANDOM_STATE)</span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Instantiate a Naive Bayes Gaussian Classifier</span></span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> GaussianNB()</span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the clasifier to the training data</span></span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a>clf.fit(X_train, y_train)</span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict the test data</span></span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> clf.predict(X_test)</span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the accuracy</span></span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy_score(y_test, y_pred)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Precision: </span><span class="sc">{</span>precision_score(y_test, y_pred, average <span class="op">=</span> <span class="st">'weighted'</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-51"><a href="#cb9-51" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"F1 Score: </span><span class="sc">{</span>f1_score(y_test, y_pred, average <span class="op">=</span> <span class="st">'weighted'</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-52"><a href="#cb9-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-53"><a href="#cb9-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"First 20 Elements of True Target Data:      </span><span class="sc">{</span>y_test[:<span class="dv">20</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-54"><a href="#cb9-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"First 20 Elements of Predicted Target Data: </span><span class="sc">{</span>y_pred[:<span class="dv">20</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-55"><a href="#cb9-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-56"><a href="#cb9-56" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the confusion matrix</span></span>
<span id="cb9-57"><a href="#cb9-57" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_test, y_pred, labels <span class="op">=</span> clf.classes_)</span>
<span id="cb9-58"><a href="#cb9-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-59"><a href="#cb9-59" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the confusion matrix</span></span>
<span id="cb9-60"><a href="#cb9-60" aria-hidden="true" tabindex="-1"></a>disp <span class="op">=</span> ConfusionMatrixDisplay(confusion_matrix <span class="op">=</span> cm, display_labels <span class="op">=</span> clf.classes_)</span>
<span id="cb9-61"><a href="#cb9-61" aria-hidden="true" tabindex="-1"></a>disp.plot()</span>
<span id="cb9-62"><a href="#cb9-62" aria-hidden="true" tabindex="-1"></a>disp.ax_.set_title(<span class="st">"Confusion Matrix for Digit Classification"</span>)<span class="op">;</span></span>
<span id="cb9-63"><a href="#cb9-63" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-64"><a href="#cb9-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-65"><a href="#cb9-65" aria-hidden="true" tabindex="-1"></a><span class="fu">### Explanation</span></span>
<span id="cb9-66"><a href="#cb9-66" aria-hidden="true" tabindex="-1"></a>Here we use a Naive Byaes Model to classify handwritten digits. We split the data into training and testing sets, </span>
<span id="cb9-67"><a href="#cb9-67" aria-hidden="true" tabindex="-1"></a>and then fit the model to the training data. We then predict the test data, and print the accuracy, precision, and </span>
<span id="cb9-68"><a href="#cb9-68" aria-hidden="true" tabindex="-1"></a>F1 score. We also print the first 20 elements of the true target data, and the first 20 elements of the predicted target </span>
<span id="cb9-69"><a href="#cb9-69" aria-hidden="true" tabindex="-1"></a>data. Finally, we plot the confusion matrix. We set a RANDOM_STATE of 20 for consistency and reproducibility. The TEST_SIZE</span>
<span id="cb9-70"><a href="#cb9-70" aria-hidden="true" tabindex="-1"></a>was 0.2 or 20%, while training data was 80%. From the data we can see that the model is fairly accurate with accuracy of 0.886, </span>
<span id="cb9-71"><a href="#cb9-71" aria-hidden="true" tabindex="-1"></a>preciision of 0.900, and F1 score of 0.886. Printing out the first 20 elements, we can see that the true target data is correct </span>
<span id="cb9-72"><a href="#cb9-72" aria-hidden="true" tabindex="-1"></a>in 19/20 cases. Based on the confusion matrix we can see that 7 was misclassified as 4, a total of 6 times, and 2 was misclassified </span>
<span id="cb9-73"><a href="#cb9-73" aria-hidden="true" tabindex="-1"></a>as 8 a total of 4 times, but otherwise the model is fairly accurate with all other numbers being misclassified 4 or fewer times.</span>
<span id="cb9-74"><a href="#cb9-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-77"><a href="#cb9-77" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb9-78"><a href="#cb9-78" aria-hidden="true" tabindex="-1"></a><span class="co">## Part 2: Clustering</span></span>
<span id="cb9-79"><a href="#cb9-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-80"><a href="#cb9-80" aria-hidden="true" tabindex="-1"></a><span class="co">### Code</span></span>
<span id="cb9-83"><a href="#cb9-83" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb9-84"><a href="#cb9-84" aria-hidden="true" tabindex="-1"></a><span class="co"># Imports</span></span>
<span id="cb9-85"><a href="#cb9-85" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> DBSCAN</span>
<span id="cb9-86"><a href="#cb9-86" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_moons</span>
<span id="cb9-87"><a href="#cb9-87" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb9-88"><a href="#cb9-88" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb9-89"><a href="#cb9-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-90"><a href="#cb9-90" aria-hidden="true" tabindex="-1"></a><span class="co"># Helper method that plots the clusters generated by DBSCAN from </span></span>
<span id="cb9-91"><a href="#cb9-91" aria-hidden="true" tabindex="-1"></a><span class="co"># handson-ml3 in 09_unsupervised_learning.ipynb</span></span>
<span id="cb9-92"><a href="#cb9-92" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_dbscan(dbscan, X, size, show_xlabels<span class="op">=</span><span class="va">True</span>, show_ylabels<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb9-93"><a href="#cb9-93" aria-hidden="true" tabindex="-1"></a>    core_mask <span class="op">=</span> np.zeros_like(dbscan.labels_, dtype<span class="op">=</span><span class="bu">bool</span>)</span>
<span id="cb9-94"><a href="#cb9-94" aria-hidden="true" tabindex="-1"></a>    core_mask[dbscan.core_sample_indices_] <span class="op">=</span> <span class="va">True</span></span>
<span id="cb9-95"><a href="#cb9-95" aria-hidden="true" tabindex="-1"></a>    anomalies_mask <span class="op">=</span> dbscan.labels_ <span class="op">==</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb9-96"><a href="#cb9-96" aria-hidden="true" tabindex="-1"></a>    non_core_mask <span class="op">=</span> <span class="op">~</span>(core_mask <span class="op">|</span> anomalies_mask)</span>
<span id="cb9-97"><a href="#cb9-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-98"><a href="#cb9-98" aria-hidden="true" tabindex="-1"></a>    cores <span class="op">=</span> dbscan.components_</span>
<span id="cb9-99"><a href="#cb9-99" aria-hidden="true" tabindex="-1"></a>    anomalies <span class="op">=</span> X[anomalies_mask]</span>
<span id="cb9-100"><a href="#cb9-100" aria-hidden="true" tabindex="-1"></a>    non_cores <span class="op">=</span> X[non_core_mask]</span>
<span id="cb9-101"><a href="#cb9-101" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-102"><a href="#cb9-102" aria-hidden="true" tabindex="-1"></a>    plt.scatter(cores[:, <span class="dv">0</span>], cores[:, <span class="dv">1</span>],</span>
<span id="cb9-103"><a href="#cb9-103" aria-hidden="true" tabindex="-1"></a>                c<span class="op">=</span>dbscan.labels_[core_mask], marker<span class="op">=</span><span class="st">'o'</span>, s<span class="op">=</span>size, cmap<span class="op">=</span><span class="st">"Paired"</span>)</span>
<span id="cb9-104"><a href="#cb9-104" aria-hidden="true" tabindex="-1"></a>    plt.scatter(cores[:, <span class="dv">0</span>], cores[:, <span class="dv">1</span>], marker<span class="op">=</span><span class="st">'*'</span>, s<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb9-105"><a href="#cb9-105" aria-hidden="true" tabindex="-1"></a>                c<span class="op">=</span>dbscan.labels_[core_mask])</span>
<span id="cb9-106"><a href="#cb9-106" aria-hidden="true" tabindex="-1"></a>    plt.scatter(anomalies[:, <span class="dv">0</span>], anomalies[:, <span class="dv">1</span>],</span>
<span id="cb9-107"><a href="#cb9-107" aria-hidden="true" tabindex="-1"></a>                c<span class="op">=</span><span class="st">"r"</span>, marker<span class="op">=</span><span class="st">"x"</span>, s<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb9-108"><a href="#cb9-108" aria-hidden="true" tabindex="-1"></a>    plt.scatter(non_cores[:, <span class="dv">0</span>], non_cores[:, <span class="dv">1</span>],</span>
<span id="cb9-109"><a href="#cb9-109" aria-hidden="true" tabindex="-1"></a>                c<span class="op">=</span>dbscan.labels_[non_core_mask], marker<span class="op">=</span><span class="st">"."</span>)</span>
<span id="cb9-110"><a href="#cb9-110" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> show_xlabels:</span>
<span id="cb9-111"><a href="#cb9-111" aria-hidden="true" tabindex="-1"></a>        plt.xlabel(<span class="st">"$x_1$"</span>)</span>
<span id="cb9-112"><a href="#cb9-112" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb9-113"><a href="#cb9-113" aria-hidden="true" tabindex="-1"></a>        plt.tick_params(labelbottom<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb9-114"><a href="#cb9-114" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> show_ylabels:</span>
<span id="cb9-115"><a href="#cb9-115" aria-hidden="true" tabindex="-1"></a>        plt.ylabel(<span class="st">"$x_2$"</span>, rotation<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb9-116"><a href="#cb9-116" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb9-117"><a href="#cb9-117" aria-hidden="true" tabindex="-1"></a>        plt.tick_params(labelleft<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb9-118"><a href="#cb9-118" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f"eps=</span><span class="sc">{</span>dbscan<span class="sc">.</span>eps<span class="sc">:.2f}</span><span class="ss">, min_samples=</span><span class="sc">{</span>dbscan<span class="sc">.</span>min_samples<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-119"><a href="#cb9-119" aria-hidden="true" tabindex="-1"></a>    plt.grid()</span>
<span id="cb9-120"><a href="#cb9-120" aria-hidden="true" tabindex="-1"></a>    plt.gca().set_axisbelow(<span class="va">True</span>)</span>
<span id="cb9-121"><a href="#cb9-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-122"><a href="#cb9-122" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a dataset of two semicircles</span></span>
<span id="cb9-123"><a href="#cb9-123" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_moons(n_samples <span class="op">=</span> <span class="dv">500</span>)</span>
<span id="cb9-124"><a href="#cb9-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-125"><a href="#cb9-125" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the DBSCAN clustering algorithm</span></span>
<span id="cb9-126"><a href="#cb9-126" aria-hidden="true" tabindex="-1"></a>db <span class="op">=</span> DBSCAN(eps <span class="op">=</span> <span class="fl">0.3</span>)</span>
<span id="cb9-127"><a href="#cb9-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-128"><a href="#cb9-128" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the data</span></span>
<span id="cb9-129"><a href="#cb9-129" aria-hidden="true" tabindex="-1"></a>db.fit(X)</span>
<span id="cb9-130"><a href="#cb9-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-131"><a href="#cb9-131" aria-hidden="true" tabindex="-1"></a><span class="co"># Store the labels in a more readable field</span></span>
<span id="cb9-132"><a href="#cb9-132" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> db.labels_</span>
<span id="cb9-133"><a href="#cb9-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-134"><a href="#cb9-134" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the estimated number of clusters and noise points</span></span>
<span id="cb9-135"><a href="#cb9-135" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Estimated number of clusters: </span><span class="sc">{</span><span class="bu">len</span>(<span class="bu">set</span>(labels)) <span class="op">-</span> (<span class="dv">1</span> <span class="cf">if</span> <span class="op">-</span><span class="dv">1</span> <span class="kw">in</span> labels <span class="cf">else</span> <span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-136"><a href="#cb9-136" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Estimated number of noise points: </span><span class="sc">{</span><span class="bu">list</span>(labels)<span class="sc">.</span>count(<span class="op">-</span><span class="dv">1</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-137"><a href="#cb9-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-138"><a href="#cb9-138" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the data</span></span>
<span id="cb9-139"><a href="#cb9-139" aria-hidden="true" tabindex="-1"></a>plot_dbscan(db, X, size <span class="op">=</span> <span class="dv">500</span>)</span>
<span id="cb9-140"><a href="#cb9-140" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-141"><a href="#cb9-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-142"><a href="#cb9-142" aria-hidden="true" tabindex="-1"></a><span class="fu">### Explanation</span></span>
<span id="cb9-143"><a href="#cb9-143" aria-hidden="true" tabindex="-1"></a>Here we use the DBSCAN clustering algorithm to cluster a dataset of two semicircles. We set the eps to 0.3, and fit the data.</span>
<span id="cb9-144"><a href="#cb9-144" aria-hidden="true" tabindex="-1"></a>We then print the estimated number of clusters and noise points. We can see that the estimated number of clusters is 2, and the</span>
<span id="cb9-145"><a href="#cb9-145" aria-hidden="true" tabindex="-1"></a>estimated number of noise points is 0. We can see that the clusters are very accurate, with no noise points. We set the RANDOM_STATE</span>
<span id="cb9-146"><a href="#cb9-146" aria-hidden="true" tabindex="-1"></a>to 20 for consistency and reproducibility. We print out the estimated number of clusters and noise points, and then plot the data.</span>
<span id="cb9-147"><a href="#cb9-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-150"><a href="#cb9-150" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb9-151"><a href="#cb9-151" aria-hidden="true" tabindex="-1"></a><span class="co">## Part 3: Linear and Nonlinear Regression</span></span>
<span id="cb9-152"><a href="#cb9-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-153"><a href="#cb9-153" aria-hidden="true" tabindex="-1"></a><span class="co">### Code</span></span>
<span id="cb9-156"><a href="#cb9-156" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb9-157"><a href="#cb9-157" aria-hidden="true" tabindex="-1"></a><span class="co"># Imports</span></span>
<span id="cb9-158"><a href="#cb9-158" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb9-159"><a href="#cb9-159" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> PolynomialFeatures</span>
<span id="cb9-160"><a href="#cb9-160" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb9-161"><a href="#cb9-161" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb9-162"><a href="#cb9-162" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb9-163"><a href="#cb9-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-164"><a href="#cb9-164" aria-hidden="true" tabindex="-1"></a>np.set_printoptions(precision <span class="op">=</span> <span class="dv">10</span>)</span>
<span id="cb9-165"><a href="#cb9-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-166"><a href="#cb9-166" aria-hidden="true" tabindex="-1"></a><span class="co"># Constants for test size, and random state</span></span>
<span id="cb9-167"><a href="#cb9-167" aria-hidden="true" tabindex="-1"></a>TEST_SIZE <span class="op">=</span> <span class="fl">0.2</span></span>
<span id="cb9-168"><a href="#cb9-168" aria-hidden="true" tabindex="-1"></a>RANDOM_STATE <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb9-169"><a href="#cb9-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-170"><a href="#cb9-170" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the random seed</span></span>
<span id="cb9-171"><a href="#cb9-171" aria-hidden="true" tabindex="-1"></a>np.random.seed(RANDOM_STATE)</span>
<span id="cb9-172"><a href="#cb9-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-173"><a href="#cb9-173" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a dataset of 500 points between -2pi and 2pi and their sin values</span></span>
<span id="cb9-174"><a href="#cb9-174" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.random.uniform(<span class="op">-</span><span class="dv">2</span> <span class="op">*</span> np.pi, <span class="dv">2</span> <span class="op">*</span> np.pi, size <span class="op">=</span> (<span class="dv">500</span>, <span class="dv">1</span>))</span>
<span id="cb9-175"><a href="#cb9-175" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.sin(X)</span>
<span id="cb9-176"><a href="#cb9-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-177"><a href="#cb9-177" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data into training and testing sets</span></span>
<span id="cb9-178"><a href="#cb9-178" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, </span>
<span id="cb9-179"><a href="#cb9-179" aria-hidden="true" tabindex="-1"></a>                                                    y, </span>
<span id="cb9-180"><a href="#cb9-180" aria-hidden="true" tabindex="-1"></a>                                                    test_size <span class="op">=</span> TEST_SIZE, </span>
<span id="cb9-181"><a href="#cb9-181" aria-hidden="true" tabindex="-1"></a>                                                    shuffle <span class="op">=</span> <span class="va">True</span>, </span>
<span id="cb9-182"><a href="#cb9-182" aria-hidden="true" tabindex="-1"></a>                                                    random_state <span class="op">=</span> RANDOM_STATE)</span>
<span id="cb9-183"><a href="#cb9-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-184"><a href="#cb9-184" aria-hidden="true" tabindex="-1"></a><span class="co"># Sort the test data</span></span>
<span id="cb9-185"><a href="#cb9-185" aria-hidden="true" tabindex="-1"></a>indices <span class="op">=</span> np.argsort(X_test, axis <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb9-186"><a href="#cb9-186" aria-hidden="true" tabindex="-1"></a>X_test_sorted <span class="op">=</span> X_test[indices].ravel()</span>
<span id="cb9-187"><a href="#cb9-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-188"><a href="#cb9-188" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a figure to plot the data</span></span>
<span id="cb9-189"><a href="#cb9-189" aria-hidden="true" tabindex="-1"></a>figure <span class="op">=</span> plt.figure(figsize <span class="op">=</span> (<span class="dv">12</span>, <span class="dv">12</span>))</span>
<span id="cb9-190"><a href="#cb9-190" aria-hidden="true" tabindex="-1"></a>figure.suptitle(<span class="st">"Graphing Linear and Polynomial Regression Models for a </span><span class="ch">\</span></span>
<span id="cb9-191"><a href="#cb9-191" aria-hidden="true" tabindex="-1"></a><span class="st">                 Sin Function with Different Degrees"</span>)</span>
<span id="cb9-192"><a href="#cb9-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-193"><a href="#cb9-193" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the linear regression model for each degree between 1 and 9</span></span>
<span id="cb9-194"><a href="#cb9-194" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> degree <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">10</span>):</span>
<span id="cb9-195"><a href="#cb9-195" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-196"><a href="#cb9-196" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a linear regression model and a polynomial features model</span></span>
<span id="cb9-197"><a href="#cb9-197" aria-hidden="true" tabindex="-1"></a>    regr <span class="op">=</span> LinearRegression()</span>
<span id="cb9-198"><a href="#cb9-198" aria-hidden="true" tabindex="-1"></a>    poly <span class="op">=</span> PolynomialFeatures(degree <span class="op">=</span> degree)</span>
<span id="cb9-199"><a href="#cb9-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-200"><a href="#cb9-200" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit the regression model to the training data</span></span>
<span id="cb9-201"><a href="#cb9-201" aria-hidden="true" tabindex="-1"></a>    X_poly <span class="op">=</span> poly.fit_transform(X_train)</span>
<span id="cb9-202"><a href="#cb9-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-203"><a href="#cb9-203" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit the polynomial features model to the training data</span></span>
<span id="cb9-204"><a href="#cb9-204" aria-hidden="true" tabindex="-1"></a>    regr.fit(X_poly, y_train)</span>
<span id="cb9-205"><a href="#cb9-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-206"><a href="#cb9-206" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Transform the test data</span></span>
<span id="cb9-207"><a href="#cb9-207" aria-hidden="true" tabindex="-1"></a>    X_test_poly <span class="op">=</span> poly.transform(X_test)</span>
<span id="cb9-208"><a href="#cb9-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-209"><a href="#cb9-209" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Predict the test data</span></span>
<span id="cb9-210"><a href="#cb9-210" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> regr.predict(X_test_poly)</span>
<span id="cb9-211"><a href="#cb9-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-212"><a href="#cb9-212" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sort the predicted data</span></span>
<span id="cb9-213"><a href="#cb9-213" aria-hidden="true" tabindex="-1"></a>    regr_y_pred <span class="op">=</span> y_pred[indices].ravel()</span>
<span id="cb9-214"><a href="#cb9-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-215"><a href="#cb9-215" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot the data</span></span>
<span id="cb9-216"><a href="#cb9-216" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> figure.add_subplot(<span class="dv">3</span>, <span class="dv">3</span>, degree)</span>
<span id="cb9-217"><a href="#cb9-217" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f"</span><span class="sc">{</span>degree<span class="sc">}</span><span class="ss"> Degree(s)"</span>)</span>
<span id="cb9-218"><a href="#cb9-218" aria-hidden="true" tabindex="-1"></a>    ax.scatter(X, y, label <span class="op">=</span> <span class="st">"Original Data"</span>, s <span class="op">=</span> <span class="dv">10</span>, color <span class="op">=</span> <span class="st">"blue"</span>)</span>
<span id="cb9-219"><a href="#cb9-219" aria-hidden="true" tabindex="-1"></a>    ax.plot(X_test_sorted, </span>
<span id="cb9-220"><a href="#cb9-220" aria-hidden="true" tabindex="-1"></a>            regr_y_pred, </span>
<span id="cb9-221"><a href="#cb9-221" aria-hidden="true" tabindex="-1"></a>            label <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>degree<span class="sc">}</span><span class="ss"> Degree Polynomial Regression Model"</span>, </span>
<span id="cb9-222"><a href="#cb9-222" aria-hidden="true" tabindex="-1"></a>            color <span class="op">=</span> <span class="st">"red"</span>, </span>
<span id="cb9-223"><a href="#cb9-223" aria-hidden="true" tabindex="-1"></a>            linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb9-224"><a href="#cb9-224" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-225"><a href="#cb9-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-226"><a href="#cb9-226" aria-hidden="true" tabindex="-1"></a><span class="fu">### Explanation</span></span>
<span id="cb9-227"><a href="#cb9-227" aria-hidden="true" tabindex="-1"></a>Here we use a linear regression model to predict the sin function. We create a dataset of 500 points between -2pi and 2pi and </span>
<span id="cb9-228"><a href="#cb9-228" aria-hidden="true" tabindex="-1"></a>their sin values. We then split the data into training and testing sets. We then sort the test data to print a nice line graph. </span>
<span id="cb9-229"><a href="#cb9-229" aria-hidden="true" tabindex="-1"></a>We then create a figure to plot the data. We then plot the linear regression model for each degree between 1 and 9. We set the</span>
<span id="cb9-230"><a href="#cb9-230" aria-hidden="true" tabindex="-1"></a>RANDOM_STATE to 20 for consistency and reproducibility. We can see that the higher the degree, the more accurate the model is.</span>
<span id="cb9-231"><a href="#cb9-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-232"><a href="#cb9-232" aria-hidden="true" tabindex="-1"></a><span class="fu">## Part 4: Classification</span></span>
<span id="cb9-233"><a href="#cb9-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-234"><a href="#cb9-234" aria-hidden="true" tabindex="-1"></a><span class="fu">### Code</span></span>
<span id="cb9-237"><a href="#cb9-237" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb9-238"><a href="#cb9-238" aria-hidden="true" tabindex="-1"></a><span class="co"># Imports</span></span>
<span id="cb9-239"><a href="#cb9-239" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb9-240"><a href="#cb9-240" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb9-241"><a href="#cb9-241" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb9-242"><a href="#cb9-242" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_breast_cancer</span>
<span id="cb9-243"><a href="#cb9-243" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb9-244"><a href="#cb9-244" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_curve, precision_recall_curve, confusion_matrix</span>
<span id="cb9-245"><a href="#cb9-245" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> ConfusionMatrixDisplay, PrecisionRecallDisplay</span>
<span id="cb9-246"><a href="#cb9-246" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> RocCurveDisplay</span>
<span id="cb9-247"><a href="#cb9-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-248"><a href="#cb9-248" aria-hidden="true" tabindex="-1"></a><span class="co"># Instantiate the classifiers</span></span>
<span id="cb9-249"><a href="#cb9-249" aria-hidden="true" tabindex="-1"></a>classifiers <span class="op">=</span> [DecisionTreeClassifier(), </span>
<span id="cb9-250"><a href="#cb9-250" aria-hidden="true" tabindex="-1"></a>               KNeighborsClassifier(), </span>
<span id="cb9-251"><a href="#cb9-251" aria-hidden="true" tabindex="-1"></a>               RandomForestClassifier()]</span>
<span id="cb9-252"><a href="#cb9-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-253"><a href="#cb9-253" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the data</span></span>
<span id="cb9-254"><a href="#cb9-254" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> load_breast_cancer(return_X_y <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb9-255"><a href="#cb9-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-256"><a href="#cb9-256" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data</span></span>
<span id="cb9-257"><a href="#cb9-257" aria-hidden="true" tabindex="-1"></a>X_test, X_train, y_test, y_train <span class="op">=</span> train_test_split(X, </span>
<span id="cb9-258"><a href="#cb9-258" aria-hidden="true" tabindex="-1"></a>                                                    y, </span>
<span id="cb9-259"><a href="#cb9-259" aria-hidden="true" tabindex="-1"></a>                                                    test_size <span class="op">=</span> TEST_SIZE, </span>
<span id="cb9-260"><a href="#cb9-260" aria-hidden="true" tabindex="-1"></a>                                                    shuffle <span class="op">=</span> <span class="va">True</span>, </span>
<span id="cb9-261"><a href="#cb9-261" aria-hidden="true" tabindex="-1"></a>                                                    random_state <span class="op">=</span> RANDOM_STATE)</span>
<span id="cb9-262"><a href="#cb9-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-263"><a href="#cb9-263" aria-hidden="true" tabindex="-1"></a>figure <span class="op">=</span> plt.figure(figsize <span class="op">=</span> (<span class="dv">15</span>, <span class="dv">15</span>))</span>
<span id="cb9-264"><a href="#cb9-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-265"><a href="#cb9-265" aria-hidden="true" tabindex="-1"></a><span class="co"># Iterate through the classifiers</span></span>
<span id="cb9-266"><a href="#cb9-266" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, clf <span class="kw">in</span> <span class="bu">enumerate</span>(classifiers):</span>
<span id="cb9-267"><a href="#cb9-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-268"><a href="#cb9-268" aria-hidden="true" tabindex="-1"></a>    idx <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb9-269"><a href="#cb9-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-270"><a href="#cb9-270" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get the name of the classifier</span></span>
<span id="cb9-271"><a href="#cb9-271" aria-hidden="true" tabindex="-1"></a>    name <span class="op">=</span> clf.__class__.<span class="va">__name__</span></span>
<span id="cb9-272"><a href="#cb9-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-273"><a href="#cb9-273" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit the classifier to the training data</span></span>
<span id="cb9-274"><a href="#cb9-274" aria-hidden="true" tabindex="-1"></a>    clf.fit(X_train, y_train)</span>
<span id="cb9-275"><a href="#cb9-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-276"><a href="#cb9-276" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Predict the test data</span></span>
<span id="cb9-277"><a href="#cb9-277" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> clf.predict(X_test)</span>
<span id="cb9-278"><a href="#cb9-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-279"><a href="#cb9-279" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate info about the ROC Curve, Precision Recall Curve, and Confusion Matrix</span></span>
<span id="cb9-280"><a href="#cb9-280" aria-hidden="true" tabindex="-1"></a>    precision, recall, thresholds <span class="op">=</span> precision_recall_curve(y_test, y_pred)</span>
<span id="cb9-281"><a href="#cb9-281" aria-hidden="true" tabindex="-1"></a>    fpr, tpr, thresholds <span class="op">=</span> roc_curve(y_test, y_pred)</span>
<span id="cb9-282"><a href="#cb9-282" aria-hidden="true" tabindex="-1"></a>    cm <span class="op">=</span> confusion_matrix(y_test, y_pred, labels <span class="op">=</span> clf.classes_)</span>
<span id="cb9-283"><a href="#cb9-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-284"><a href="#cb9-284" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create the displays</span></span>
<span id="cb9-285"><a href="#cb9-285" aria-hidden="true" tabindex="-1"></a>    precision_recall_curve_display <span class="op">=</span> PrecisionRecallDisplay(precision <span class="op">=</span> precision, </span>
<span id="cb9-286"><a href="#cb9-286" aria-hidden="true" tabindex="-1"></a>                                                            recall <span class="op">=</span> recall)</span>
<span id="cb9-287"><a href="#cb9-287" aria-hidden="true" tabindex="-1"></a>    roc_curve_display <span class="op">=</span> RocCurveDisplay(fpr <span class="op">=</span> fpr, tpr <span class="op">=</span> tpr)</span>
<span id="cb9-288"><a href="#cb9-288" aria-hidden="true" tabindex="-1"></a>    confusion_matrix_display <span class="op">=</span> ConfusionMatrixDisplay(confusion_matrix <span class="op">=</span> cm, </span>
<span id="cb9-289"><a href="#cb9-289" aria-hidden="true" tabindex="-1"></a>                                                      display_labels <span class="op">=</span> clf.classes_)</span>
<span id="cb9-290"><a href="#cb9-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-291"><a href="#cb9-291" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot the ROC and Precision Recall Curves</span></span>
<span id="cb9-292"><a href="#cb9-292" aria-hidden="true" tabindex="-1"></a>    ax1 <span class="op">=</span> figure.add_subplot(<span class="dv">3</span>, <span class="dv">3</span>, idx)</span>
<span id="cb9-293"><a href="#cb9-293" aria-hidden="true" tabindex="-1"></a>    ax1.set_title(<span class="ss">f"</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss"> PR Curve"</span>)</span>
<span id="cb9-294"><a href="#cb9-294" aria-hidden="true" tabindex="-1"></a>    precision_recall_curve_display.plot(ax <span class="op">=</span> ax1, label <span class="op">=</span> <span class="st">"Precision Recall Curve"</span>)</span>
<span id="cb9-295"><a href="#cb9-295" aria-hidden="true" tabindex="-1"></a>    ax1.legend_.remove()</span>
<span id="cb9-296"><a href="#cb9-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-297"><a href="#cb9-297" aria-hidden="true" tabindex="-1"></a>    ax2 <span class="op">=</span> figure.add_subplot(<span class="dv">3</span>, <span class="dv">3</span>, idx <span class="op">+</span> <span class="bu">len</span>(classifiers))</span>
<span id="cb9-298"><a href="#cb9-298" aria-hidden="true" tabindex="-1"></a>    ax2.set_title(<span class="ss">f"</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss"> ROC Curve"</span>)</span>
<span id="cb9-299"><a href="#cb9-299" aria-hidden="true" tabindex="-1"></a>    roc_curve_display.plot(ax <span class="op">=</span> ax2, label <span class="op">=</span> <span class="st">"ROC Curve"</span>)</span>
<span id="cb9-300"><a href="#cb9-300" aria-hidden="true" tabindex="-1"></a>    ax2.legend_.remove()</span>
<span id="cb9-301"><a href="#cb9-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-302"><a href="#cb9-302" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot the confusion matrix</span></span>
<span id="cb9-303"><a href="#cb9-303" aria-hidden="true" tabindex="-1"></a>    ax3 <span class="op">=</span> figure.add_subplot(<span class="dv">3</span>, <span class="dv">3</span>, idx <span class="op">+</span> <span class="dv">2</span> <span class="op">*</span> <span class="bu">len</span>(classifiers))</span>
<span id="cb9-304"><a href="#cb9-304" aria-hidden="true" tabindex="-1"></a>    ax3.set_title(<span class="ss">f"</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss"> Confusion Matrix"</span>, fontsize <span class="op">=</span> <span class="dv">10</span>)</span>
<span id="cb9-305"><a href="#cb9-305" aria-hidden="true" tabindex="-1"></a>    confusion_matrix_display.plot(ax <span class="op">=</span> ax3)</span>
<span id="cb9-306"><a href="#cb9-306" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-307"><a href="#cb9-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-308"><a href="#cb9-308" aria-hidden="true" tabindex="-1"></a><span class="fu">### Explanation</span></span>
<span id="cb9-309"><a href="#cb9-309" aria-hidden="true" tabindex="-1"></a>Here we use three different classifiers to classify breast cancer data. We use a Decision Tree Classifier, a K Neighbors Classifier,</span>
<span id="cb9-310"><a href="#cb9-310" aria-hidden="true" tabindex="-1"></a>and a Random Forest Classifier. We split the data into training and testing sets. We then fit the classifiers to the training data,</span>
<span id="cb9-311"><a href="#cb9-311" aria-hidden="true" tabindex="-1"></a>and predict the test data. We then calculate info about the ROC Curve, Precision Recall Curve, and Confusion Matrix. We then create</span>
<span id="cb9-312"><a href="#cb9-312" aria-hidden="true" tabindex="-1"></a>the displays for the ROC and Precision Recall Curves, and the Confusion Matrix. We set the RANDOM_STATE to 20 for consistency and</span>
<span id="cb9-313"><a href="#cb9-313" aria-hidden="true" tabindex="-1"></a>reproducibility. We can see that the Random Forest Classifier is the most accurate, with the highest precision and recall, and the</span>
<span id="cb9-314"><a href="#cb9-314" aria-hidden="true" tabindex="-1"></a>highest area under the ROC curve. The K Neighbors Classifier is the least accurate, with the most false positives and false negatives</span>
<span id="cb9-315"><a href="#cb9-315" aria-hidden="true" tabindex="-1"></a>in the confusion matrix. The Decision Tree Classifier had the most false misclassification of the 1 class, with 30 false negatives.</span>
<span id="cb9-316"><a href="#cb9-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-317"><a href="#cb9-317" aria-hidden="true" tabindex="-1"></a><span class="fu">## Part 5: Anomaly/Outlier Detection</span></span>
<span id="cb9-318"><a href="#cb9-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-319"><a href="#cb9-319" aria-hidden="true" tabindex="-1"></a><span class="fu">### Code</span></span>
<span id="cb9-322"><a href="#cb9-322" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb9-323"><a href="#cb9-323" aria-hidden="true" tabindex="-1"></a><span class="co"># Imports</span></span>
<span id="cb9-324"><a href="#cb9-324" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> DBSCAN</span>
<span id="cb9-325"><a href="#cb9-325" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_moons</span>
<span id="cb9-326"><a href="#cb9-326" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb9-327"><a href="#cb9-327" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb9-328"><a href="#cb9-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-329"><a href="#cb9-329" aria-hidden="true" tabindex="-1"></a>RANDOM_STATE <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb9-330"><a href="#cb9-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-331"><a href="#cb9-331" aria-hidden="true" tabindex="-1"></a><span class="co"># Helper method that plots the clusters generated by DBSCAN from </span></span>
<span id="cb9-332"><a href="#cb9-332" aria-hidden="true" tabindex="-1"></a><span class="co"># handson-ml3 in 09_unsupervised_learning.ipynb</span></span>
<span id="cb9-333"><a href="#cb9-333" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_dbscan(dbscan, X, size, show_xlabels<span class="op">=</span><span class="va">True</span>, show_ylabels<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb9-334"><a href="#cb9-334" aria-hidden="true" tabindex="-1"></a>    core_mask <span class="op">=</span> np.zeros_like(dbscan.labels_, dtype<span class="op">=</span><span class="bu">bool</span>)</span>
<span id="cb9-335"><a href="#cb9-335" aria-hidden="true" tabindex="-1"></a>    core_mask[dbscan.core_sample_indices_] <span class="op">=</span> <span class="va">True</span></span>
<span id="cb9-336"><a href="#cb9-336" aria-hidden="true" tabindex="-1"></a>    anomalies_mask <span class="op">=</span> dbscan.labels_ <span class="op">==</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb9-337"><a href="#cb9-337" aria-hidden="true" tabindex="-1"></a>    non_core_mask <span class="op">=</span> <span class="op">~</span>(core_mask <span class="op">|</span> anomalies_mask)</span>
<span id="cb9-338"><a href="#cb9-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-339"><a href="#cb9-339" aria-hidden="true" tabindex="-1"></a>    cores <span class="op">=</span> dbscan.components_</span>
<span id="cb9-340"><a href="#cb9-340" aria-hidden="true" tabindex="-1"></a>    anomalies <span class="op">=</span> X[anomalies_mask]</span>
<span id="cb9-341"><a href="#cb9-341" aria-hidden="true" tabindex="-1"></a>    non_cores <span class="op">=</span> X[non_core_mask]</span>
<span id="cb9-342"><a href="#cb9-342" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-343"><a href="#cb9-343" aria-hidden="true" tabindex="-1"></a>    plt.scatter(cores[:, <span class="dv">0</span>], cores[:, <span class="dv">1</span>],</span>
<span id="cb9-344"><a href="#cb9-344" aria-hidden="true" tabindex="-1"></a>                c<span class="op">=</span>dbscan.labels_[core_mask], marker<span class="op">=</span><span class="st">'o'</span>, s<span class="op">=</span>size, cmap<span class="op">=</span><span class="st">"Paired"</span>)</span>
<span id="cb9-345"><a href="#cb9-345" aria-hidden="true" tabindex="-1"></a>    plt.scatter(cores[:, <span class="dv">0</span>], cores[:, <span class="dv">1</span>], marker<span class="op">=</span><span class="st">'*'</span>, s<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb9-346"><a href="#cb9-346" aria-hidden="true" tabindex="-1"></a>                c<span class="op">=</span>dbscan.labels_[core_mask])</span>
<span id="cb9-347"><a href="#cb9-347" aria-hidden="true" tabindex="-1"></a>    plt.scatter(anomalies[:, <span class="dv">0</span>], anomalies[:, <span class="dv">1</span>],</span>
<span id="cb9-348"><a href="#cb9-348" aria-hidden="true" tabindex="-1"></a>                c<span class="op">=</span><span class="st">"r"</span>, marker<span class="op">=</span><span class="st">"x"</span>, s<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb9-349"><a href="#cb9-349" aria-hidden="true" tabindex="-1"></a>    plt.scatter(non_cores[:, <span class="dv">0</span>], non_cores[:, <span class="dv">1</span>],</span>
<span id="cb9-350"><a href="#cb9-350" aria-hidden="true" tabindex="-1"></a>                c<span class="op">=</span>dbscan.labels_[non_core_mask], marker<span class="op">=</span><span class="st">"."</span>)</span>
<span id="cb9-351"><a href="#cb9-351" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> show_xlabels:</span>
<span id="cb9-352"><a href="#cb9-352" aria-hidden="true" tabindex="-1"></a>        plt.xlabel(<span class="st">"$x_1$"</span>)</span>
<span id="cb9-353"><a href="#cb9-353" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb9-354"><a href="#cb9-354" aria-hidden="true" tabindex="-1"></a>        plt.tick_params(labelbottom<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb9-355"><a href="#cb9-355" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> show_ylabels:</span>
<span id="cb9-356"><a href="#cb9-356" aria-hidden="true" tabindex="-1"></a>        plt.ylabel(<span class="st">"$x_2$"</span>, rotation<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb9-357"><a href="#cb9-357" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb9-358"><a href="#cb9-358" aria-hidden="true" tabindex="-1"></a>        plt.tick_params(labelleft<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb9-359"><a href="#cb9-359" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f"eps=</span><span class="sc">{</span>dbscan<span class="sc">.</span>eps<span class="sc">:.2f}</span><span class="ss">, min_samples=</span><span class="sc">{</span>dbscan<span class="sc">.</span>min_samples<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-360"><a href="#cb9-360" aria-hidden="true" tabindex="-1"></a>    plt.grid()</span>
<span id="cb9-361"><a href="#cb9-361" aria-hidden="true" tabindex="-1"></a>    plt.gca().set_axisbelow(<span class="va">True</span>)</span>
<span id="cb9-362"><a href="#cb9-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-363"><a href="#cb9-363" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a dataset of two semicircles</span></span>
<span id="cb9-364"><a href="#cb9-364" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_moons(n_samples <span class="op">=</span> <span class="dv">1000</span>, random_state <span class="op">=</span> RANDOM_STATE)</span>
<span id="cb9-365"><a href="#cb9-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-366"><a href="#cb9-366" aria-hidden="true" tabindex="-1"></a><span class="co"># Create 10 outlier points</span></span>
<span id="cb9-367"><a href="#cb9-367" aria-hidden="true" tabindex="-1"></a>np.random.seed(RANDOM_STATE)</span>
<span id="cb9-368"><a href="#cb9-368" aria-hidden="true" tabindex="-1"></a>X_outliers <span class="op">=</span> np.random.uniform(low <span class="op">=</span> <span class="op">-</span><span class="dv">6</span>, high <span class="op">=</span> <span class="dv">6</span>, size <span class="op">=</span> (<span class="dv">40</span>, <span class="dv">2</span>))</span>
<span id="cb9-369"><a href="#cb9-369" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.concatenate([X, X_outliers], axis <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb9-370"><a href="#cb9-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-371"><a href="#cb9-371" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the DBSCAN clustering algorithm</span></span>
<span id="cb9-372"><a href="#cb9-372" aria-hidden="true" tabindex="-1"></a>db <span class="op">=</span> DBSCAN(eps <span class="op">=</span> <span class="fl">0.3</span>)</span>
<span id="cb9-373"><a href="#cb9-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-374"><a href="#cb9-374" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the data</span></span>
<span id="cb9-375"><a href="#cb9-375" aria-hidden="true" tabindex="-1"></a>db.fit(X)</span>
<span id="cb9-376"><a href="#cb9-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-377"><a href="#cb9-377" aria-hidden="true" tabindex="-1"></a><span class="co"># Store the labels in a more readable field</span></span>
<span id="cb9-378"><a href="#cb9-378" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> db.labels_</span>
<span id="cb9-379"><a href="#cb9-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-380"><a href="#cb9-380" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the estimated number of clusters and noise points</span></span>
<span id="cb9-381"><a href="#cb9-381" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Estimated number of clusters: </span><span class="sc">{</span><span class="bu">len</span>(<span class="bu">set</span>(labels)) <span class="op">-</span> (<span class="dv">1</span> <span class="cf">if</span> <span class="op">-</span><span class="dv">1</span> <span class="kw">in</span> labels <span class="cf">else</span> <span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-382"><a href="#cb9-382" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Estimated number of noise points: </span><span class="sc">{</span><span class="bu">list</span>(labels)<span class="sc">.</span>count(<span class="op">-</span><span class="dv">1</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-383"><a href="#cb9-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-384"><a href="#cb9-384" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the data</span></span>
<span id="cb9-385"><a href="#cb9-385" aria-hidden="true" tabindex="-1"></a>plot_dbscan(db, X, size <span class="op">=</span> <span class="dv">500</span>)</span>
<span id="cb9-386"><a href="#cb9-386" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-387"><a href="#cb9-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-388"><a href="#cb9-388" aria-hidden="true" tabindex="-1"></a><span class="fu">### Explanation</span></span>
<span id="cb9-389"><a href="#cb9-389" aria-hidden="true" tabindex="-1"></a>Here we use the DBSCAN clustering algorithm to cluster a dataset of two semicircles. We set the eps to 0.3, and fit the data.</span>
<span id="cb9-390"><a href="#cb9-390" aria-hidden="true" tabindex="-1"></a>We add several outlier points to the data to see if the DBSCAN algorithm can detect them. We then print the estimated number of</span>
<span id="cb9-391"><a href="#cb9-391" aria-hidden="true" tabindex="-1"></a>clusters and noise points. We can see that the estimated number of clusters is 2, and the estimated number of noise points is 39.</span>
<span id="cb9-392"><a href="#cb9-392" aria-hidden="true" tabindex="-1"></a>We added 40 points, which means that one of the randomly placed points on the graph was not detected as an outlier, and was close</span>
<span id="cb9-393"><a href="#cb9-393" aria-hidden="true" tabindex="-1"></a>enough to one of the half moon clusters. We set the RANDOM_STATE to 20 for consistency and reproducibility. We print out the</span>
<span id="cb9-394"><a href="#cb9-394" aria-hidden="true" tabindex="-1"></a>estimated number of clusters and noise points, and then plot the data.</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>